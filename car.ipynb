{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ace49fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from torch import nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dec46583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils\n",
    "import torch.utils.data\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.4552, 0.4562, 0.4567],\n",
    "        std=[0.1928, 0.1929, 0.1895]\n",
    "    )\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder('./data/ex7-carTypes/carTypes/train', transform=transform)\n",
    "test_dataset = datasets.ImageFolder('data/ex7-carTypes/carTypes/val', transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7f10e083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image size: torch.Size([32, 3, 224, 224])\n",
      "target: tensor([3, 0, 0, 3, 1, 4, 0, 5, 5, 4, 5, 4, 0, 1, 0, 4, 3, 1, 1, 5, 2, 5, 0, 5,\n",
      "        3, 2, 3, 3, 2, 5, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for data, target in train_loader:\n",
    "    print(f'image size: {data.size()}')\n",
    "    print(f\"target: {target}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "eb3a3b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([-1.5595e-04,  3.1006e-05,  1.9247e-04])\n",
      "Std: tensor([1.0000, 1.0001, 1.0001])\n"
     ]
    }
   ],
   "source": [
    "mean = 0.0\n",
    "std = 0.0\n",
    "n_samples = 0\n",
    "for data, _ in train_loader:\n",
    "    n_samples += data.shape[0]\n",
    "    data = data.view(data.shape[0], data.shape[1], -1)\n",
    "    mean += data.mean(2).sum(0)\n",
    "    std += data.std(2).sum(0)\n",
    "mean = mean / n_samples\n",
    "std = std / n_samples\n",
    "print(f\"Mean: {mean}\")\n",
    "print(f\"Std: {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "955ba5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, use_conv3=False ,stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=input_channels, out_channels=output_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=output_channels, out_channels=output_channels, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn1 = nn.BatchNorm2d(output_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(output_channels)\n",
    "        if use_conv3:\n",
    "            self.conv3 = nn.Conv2d(in_channels=input_channels, out_channels=output_channels, kernel_size=1, stride=2)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "    \n",
    "    def forward(self, X):\n",
    "        Y = self.bn1(self.conv1(X))\n",
    "        Y = self.relu(Y)\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        return F.relu(X + Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b6e9b559",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layer, num_classes=6):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, padding=1, stride=2)\n",
    "\n",
    "        self.layer1 = nn.Sequential(*self._make_layer(block, 64, layer[0], first_block=True))\n",
    "        self.layer2 = nn.Sequential(*self._make_layer(block, 128, layer[1]))\n",
    "        self.layer3 = nn.Sequential(*self._make_layer(block, 256, layer[2]))\n",
    "        self.layer4 = nn.Sequential(*self._make_layer(block, 512, layer[3]))\n",
    "\n",
    "        self.adpavgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "    \n",
    "    def _make_layer(self, block, out_channels, blocks, stride=1, first_block=False):\n",
    "        layers = []\n",
    "        for i in range(blocks):\n",
    "            if i == 0 and not first_block:\n",
    "                layers.append(block(self.in_channels, out_channels, use_conv3=True, stride=2))\n",
    "                self.in_channels = out_channels\n",
    "            else:\n",
    "                layers.append(block(self.in_channels, out_channels, stride=1))\n",
    "        return layers\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.bn1(self.conv1(x))\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.adpavgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        out = self.fc(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f3388252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0141,  0.1729, -0.3993,  0.7125, -0.4176, -0.6316]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet(Residual, [2,2,2,2])\n",
    "X = torch.rand((1, 3, 224, 224))\n",
    "model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1137136e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, train_loss: 1.1141, test_loss: 1.1695, Accuracy: 0.65\n",
      "Epoch: 2, train_loss: 0.5152, test_loss: 0.9735, Accuracy: 0.6666666666666666\n",
      "Epoch: 3, train_loss: 0.3229, test_loss: 0.6224, Accuracy: 0.8\n",
      "Epoch: 4, train_loss: 0.2586, test_loss: 0.2939, Accuracy: 0.9166666666666666\n",
      "Epoch: 5, train_loss: 0.1995, test_loss: 0.4335, Accuracy: 0.8666666666666667\n",
      "Epoch: 6, train_loss: 0.1994, test_loss: 0.2233, Accuracy: 0.9166666666666666\n",
      "Epoch: 7, train_loss: 0.0988, test_loss: 0.5231, Accuracy: 0.8833333333333333\n",
      "Epoch: 8, train_loss: 0.1583, test_loss: 0.3243, Accuracy: 0.9166666666666666\n",
      "Epoch: 9, train_loss: 0.1197, test_loss: 0.1427, Accuracy: 0.9583333333333334\n",
      "Epoch: 10, train_loss: 0.1825, test_loss: 0.4482, Accuracy: 0.875\n",
      "Epoch: 11, train_loss: 0.1158, test_loss: 0.1914, Accuracy: 0.9\n",
      "Epoch: 12, train_loss: 0.1189, test_loss: 0.1641, Accuracy: 0.9583333333333334\n",
      "Epoch: 13, train_loss: 0.0195, test_loss: 0.1164, Accuracy: 0.9833333333333333\n",
      "Epoch: 14, train_loss: 0.0116, test_loss: 0.0925, Accuracy: 0.975\n",
      "Epoch: 15, train_loss: 0.0521, test_loss: 0.1395, Accuracy: 0.975\n",
      "Epoch: 16, train_loss: 0.0207, test_loss: 0.0658, Accuracy: 0.975\n",
      "Epoch: 17, train_loss: 0.0504, test_loss: 0.4507, Accuracy: 0.8833333333333333\n",
      "Epoch: 18, train_loss: 0.0747, test_loss: 0.3480, Accuracy: 0.9083333333333333\n",
      "Epoch: 19, train_loss: 0.0866, test_loss: 0.1386, Accuracy: 0.9583333333333334\n",
      "Epoch: 20, train_loss: 0.0375, test_loss: 0.1147, Accuracy: 0.975\n",
      "Epoch: 21, train_loss: 0.2339, test_loss: 0.2323, Accuracy: 0.9083333333333333\n",
      "Epoch: 22, train_loss: 0.1120, test_loss: 0.3660, Accuracy: 0.8916666666666667\n",
      "Epoch: 23, train_loss: 0.0192, test_loss: 0.0370, Accuracy: 0.9833333333333333\n",
      "Epoch: 24, train_loss: 0.0204, test_loss: 0.0985, Accuracy: 0.9666666666666667\n",
      "Epoch: 25, train_loss: 0.0195, test_loss: 0.2439, Accuracy: 0.9333333333333333\n",
      "Epoch: 26, train_loss: 0.0806, test_loss: 0.1141, Accuracy: 0.9666666666666667\n",
      "Epoch: 27, train_loss: 0.0175, test_loss: 0.0517, Accuracy: 0.9833333333333333\n",
      "Epoch: 28, train_loss: 0.0187, test_loss: 0.1281, Accuracy: 0.9666666666666667\n",
      "Epoch: 29, train_loss: 0.0153, test_loss: 0.1221, Accuracy: 0.9416666666666667\n",
      "Epoch: 30, train_loss: 0.1538, test_loss: 0.1350, Accuracy: 0.925\n",
      "Epoch: 31, train_loss: 0.0133, test_loss: 0.0658, Accuracy: 0.9833333333333333\n",
      "Epoch: 32, train_loss: 0.0036, test_loss: 0.0174, Accuracy: 1.0\n",
      "Epoch: 33, train_loss: 0.0045, test_loss: 0.0177, Accuracy: 1.0\n",
      "Epoch: 34, train_loss: 0.0082, test_loss: 0.0928, Accuracy: 0.9666666666666667\n",
      "Epoch: 35, train_loss: 0.1193, test_loss: 0.1102, Accuracy: 0.975\n",
      "Epoch: 36, train_loss: 0.0430, test_loss: 0.2140, Accuracy: 0.9\n",
      "Epoch: 37, train_loss: 0.1385, test_loss: 0.1328, Accuracy: 0.95\n",
      "Epoch: 38, train_loss: 0.0212, test_loss: 0.1358, Accuracy: 0.9583333333333334\n",
      "Epoch: 39, train_loss: 0.0478, test_loss: 0.1126, Accuracy: 0.95\n",
      "Epoch: 40, train_loss: 0.0058, test_loss: 0.0612, Accuracy: 0.9583333333333334\n",
      "Epoch: 41, train_loss: 0.0061, test_loss: 0.0293, Accuracy: 0.9833333333333333\n",
      "Epoch: 42, train_loss: 0.0648, test_loss: 0.2761, Accuracy: 0.9416666666666667\n",
      "EarlyStopping\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ResNet(Residual, [3,4,23,3])\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),  lr=0.0001)\n",
    "best_val_loss = float('inf')  \n",
    "patience = 10                  \n",
    "counter = 0  \n",
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for X, y in train_loader:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        acc = 0.0\n",
    "        test_loss = 0.0\n",
    "        for X, y in test_loader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            loss = criterion(pred, y)\n",
    "            test_loss += loss.item()\n",
    "            acc += (pred.argmax(dim=1) == y).sum().item()\n",
    "        \n",
    "    print(f\"Epoch: {epoch + 1}, train_loss: {train_loss / len(train_loader):.4f}, test_loss: {test_loss / len(test_loader):.4f}, Accuracy: {acc / len(test_loader.dataset)}\")\n",
    "    if test_loss < best_val_loss:\n",
    "        best_val_loss = test_loss\n",
    "        counter = 0\n",
    "        torch.save(model.state_dict(), 'ResNet101_car.pth')\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"EarlyStopping\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "87375bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.0174, Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('ResNet101_car.pth'))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    acc = 0.0\n",
    "    test_loss = 0.0\n",
    "    for X, y in test_loader:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = criterion(pred, y)\n",
    "        test_loss += loss.item()\n",
    "        acc += (pred.argmax(dim=1) == y).sum().item()\n",
    "    print(f\"test_loss: {test_loss / len(test_loader):.4f}, Accuracy: {acc / len(test_loader.dataset)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
